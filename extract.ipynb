{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ede4fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensão Comex adicionada na Stage\n",
      "Fato Comex exportação adicionada na Stage\n",
      "Fato Comex importação adicionada na Stage\n",
      "Stage de dados criada!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests as rq\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime\n",
    "from sqlalchemy import create_engine\n",
    "import psycopg2\n",
    "import time\n",
    "\n",
    "\n",
    "\n",
    "def crawler_comex():\n",
    "    link = 'https://www.gov.br/mdic/pt-br/assuntos/comercio-exterior/estatisticas/base-de-dados-bruta'\n",
    "    try:\n",
    "        resposta = rq.get(link)\n",
    "        soup = BeautifulSoup(resposta.text, 'html.parser')\n",
    "\n",
    "    except resposta.status_code != 200:  # type: ignore\n",
    "        print(\"Erro!\")\n",
    "    soup = BeautifulSoup(resposta.text, 'html.parser')\n",
    "    return soup\n",
    "    \n",
    "\n",
    "def extract_dim_table():\n",
    "    soup = crawler_comex()\n",
    "    links = soup.find_all('table',class_ = 'plain')[6]('a')\n",
    "    link_dim = [x.get('href') for x in links if x.get_text() == 'NCM']\n",
    "    return link_dim[0]\n",
    "\n",
    "def extract_fato_table():\n",
    "    soup = crawler_comex()\n",
    "    #Exportaçao\n",
    "    export_links = soup.find_all('table',class_ = 'plain')[0]('a',class_='external-link')\n",
    "\n",
    "    #Importaçãos\n",
    "    import_links = soup.find_all('table',class_ = 'plain')[1]('a',class_='external-link')\n",
    "\n",
    "    # Obter o ano atual\n",
    "    ano_atual = datetime.now().year\n",
    "\n",
    "\n",
    "    link_base_de_dados_export = [x.get('href') for x in export_links if x.get_text() == str(ano_atual)]\n",
    "    link_base_de_dados_import = [x.get('href') for x in import_links if x.get_text() == str(ano_atual)]\n",
    "    return link_base_de_dados_export[0],link_base_de_dados_import[0]\n",
    "\n",
    "def create_stage():\n",
    "    dim_folder_path_stage = r'C:\\Users\\GabrielLeal\\OneDrive - Grupo Portfolio\\Área de Trabalho\\DataOps\\landing\\dimensao'\n",
    "    fat_folder_path_stage = r'C:\\Users\\GabrielLeal\\OneDrive - Grupo Portfolio\\Área de Trabalho\\DataOps\\landing\\fato'\n",
    "\n",
    "    link_export,link_import = extract_fato_table()\n",
    "    link_dim =  extract_dim_table()\n",
    "\n",
    "\n",
    "    fat_export = pd.read_csv(link_export,sep =';',encoding='ISO-8859-1')\n",
    "    fat_import = pd.read_csv(link_import,sep =';',encoding='ISO-8859-1')\n",
    "    dim_comex = pd.read_csv(link_dim, sep=';',encoding='ISO-8859-1')\n",
    "\n",
    "    dim_comex.to_excel(dim_folder_path_stage+'/dim_landing.xlsx',index=False)\n",
    "    print(\"Dimensão Comex adicionada na landing zone\")\n",
    "\n",
    "    fat_export.to_excel(fat_folder_path_stage+'/fat_export_landing.xlsx',index=False)\n",
    "    print(\"Fato Comex exportação adicionada na landing zone\")\n",
    "    \n",
    "    fat_import.to_excel(fat_folder_path_stage+'/fat_import_landing.xlsx',index=False)\n",
    "    print(\"Fato Comex importação adicionada landing zone\")\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    create_stage()\n",
    "    print('Stage de dados criada!')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
